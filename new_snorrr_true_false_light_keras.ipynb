{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "new_snorrr_true_false_light_keras.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "Wau96yf3kimd"
      ],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "GqS5C8mDYxgg",
        "colab_type": "code",
        "outputId": "3dba5fb2-cff8-4ec9-dc19-66fad4bedfbe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "al6q3XALYrw_",
        "colab_type": "code",
        "outputId": "422e8342-c4f4-4f25-f7ec-f7ab376376fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd /content/drive/My\\ Drive/tobigs/snorrr2"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/tobigs/snorrr2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pvKS_cpfjEeS",
        "colab_type": "code",
        "outputId": "27e90af8-54bb-4771-e925-7af8cdb68283",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# !unzip raw_data.zip -d data/\n",
        "!pip install pydub"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pydub in /usr/local/lib/python3.6/dist-packages (0.23.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rkBnj-nQBabI",
        "colab_type": "code",
        "outputId": "af34a492-69b0-45b5-b601-e16c6e7e126c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mdata\u001b[0m/             new_snorrr_true_false.ipynb              raw_data.zip\n",
            "\u001b[01;34mdata_small_test\u001b[0m/  new_snorrr_true_false_light.ipynb        temp.mp3\n",
            "\u001b[01;34mmodel\u001b[0m/            new_snorrr_true_false_light_keras.ipynb  \u001b[01;34mweight\u001b[0m/\n",
            "new_snorrr.ipynb  \u001b[01;34mnoise\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wau96yf3kimd",
        "colab_type": "text"
      },
      "source": [
        "## audio.csv 만들기\n",
        "(파일 겹치는건 빼기)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lHZmp-t9kht2",
        "colab_type": "code",
        "outputId": "e0904ada-25cc-4b6e-8060-e76d4312f5e8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cd /content/drive/My\\ Drive/tobigs/snorrr2/data"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/tobigs/snorrr2/data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cvbpvnfUqcm8",
        "colab_type": "code",
        "outputId": "10b07bdf-9ad0-475a-b144-251906ca9f6b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34m'Male speech, man speaking'\u001b[0m/   \u001b[01;34msnoring\u001b[0m/                         \u001b[01;34mVehicle\u001b[0m/\n",
            "\u001b[01;34m'Outside, rural or natural'\u001b[0m/  \u001b[01;34m'Traffic noise, roadway noise'\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Slh3aa05kvWW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "label_info = ['Male speech, man speaking','Outside, rural or natural','snoring','Traffic noise, roadway noise','Vehicle']\n",
        "df = pd.DataFrame({\"file_name\":[], \"labels\":[]})\n",
        "for label in os.listdir():\n",
        "  if label=='__MACOSX':\n",
        "      continue\n",
        "  label_dir = os.path.join(os.getcwd(), label)\n",
        "  current_label_num = label_info.index(label)+1\n",
        "  for file in os.listdir(label_dir):\n",
        "    if file.endswith(\"mp3\"):\n",
        "      df = df.append({\"file_name\":file, \"labels\":int(current_label_num)} , ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hr3J5JVVuUq5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.labels = df['labels'].astype(int)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ul6ZEd68v700",
        "colab_type": "code",
        "outputId": "d07b392d-10fe-437a-f7b3-75da7605e9c5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "df[df.file_name.duplicated()]['file_name']"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "82     3353.mp3\n",
              "107    2550.mp3\n",
              "112    2933.mp3\n",
              "134    2762.mp3\n",
              "147    1705.mp3\n",
              "149    3272.mp3\n",
              "157    2536.mp3\n",
              "225    1522.mp3\n",
              "Name: file_name, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SgAsCM79vSDh",
        "colab_type": "code",
        "outputId": "5db26bcf-9cee-4278-c857-916da1fe2693",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "df[df['file_name'].str.find('5487.mp3')!=-1]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>file_name</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>241</th>\n",
              "      <td>5487.mp3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    file_name  labels\n",
              "241  5487.mp3       1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-yHnU0U4qakz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 중복되는건 삭제하기\n",
        "df = df[df['file_name'].isin(df[df.file_name.duplicated()]['file_name'])==False]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUsHOb6Mzqrh",
        "colab_type": "code",
        "outputId": "3444b61b-5f58-41ac-911e-a698bbaa929f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "len(df)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "227"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ULbZlXJHwxDt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.to_csv('audio.csv',index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Rc_LfVWknpm",
        "colab_type": "text"
      },
      "source": [
        "## 학습하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oWFQ2pxQks24",
        "colab_type": "code",
        "outputId": "af30ba25-b661-4bbc-bbeb-d2eb6927a1ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd /content/drive/My\\ Drive/tobigs/snorrr2"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/tobigs/snorrr2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "seP-nzVrfSPX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import librosa\n",
        "import pydub \n",
        "from fastprogress import master_bar, progress_bar\n",
        "import numpy as np\n",
        "import time\n",
        "import os\n",
        "import warnings\n",
        "from sklearn.metrics import classification_report"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yr1e22pMBNqn",
        "colab_type": "code",
        "outputId": "afd789c6-86ef-4494-9cfe-d6d856feb570",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "warnings.filterwarnings(action=\"ignore\")\n",
        "\n",
        "path1 = \"./data/Male speech, man speaking\"\n",
        "path2 = \"./data/Outside, rural or natural\"\n",
        "path3 = \"./data/snoring\"\n",
        "path4 = \"./data/Traffic noise, roadway noise\"\n",
        "path5 = \"./data/Vehicle\"\n",
        "\n",
        "df = pd.read_csv(\"./data/audio.csv\")\n",
        "train_df, test_df = train_test_split(df, test_size=0.3, random_state=42) \n",
        "# train_df, valid_df = train_test_split(df, test_size=0.2, random_state=42) \n",
        "\n",
        "train_df = train_df.reset_index()\n",
        "# valid_df = valid_df.reset_index()\n",
        "test_df = test_df.reset_index()\n",
        "print(train_df[\"labels\"].value_counts())\n",
        "# print(test_df[\"labels\"].value_counts())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3    1461\n",
            "1    1039\n",
            "2     742\n",
            "5     491\n",
            "4     306\n",
            "Name: labels, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-OhsmPrBs-5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pydub import AudioSegment\n",
        "def freq_augmentation(y, sr):\n",
        "    switch = np.random.randint(1,3)\n",
        "    if(switch==1): #고음\n",
        "        rate = np.random.uniform(2, 5)\n",
        "    elif(switch==2): #저음\n",
        "        rate = np.random.uniform(-5, -2)\n",
        "    y = librosa.effects.pitch_shift(y, sr, n_steps=rate)\n",
        "    return y\n",
        "\n",
        "def adding_random_noise(y, noise_rate=0.005):\n",
        "    rn = np.random.randn(len(y))\n",
        "    data_rn = y + noise_rate*rn\n",
        "    return data_rn\n",
        "\n",
        "def minus_sound(y):\n",
        "    temp_numpy = (-1)*y\n",
        "    return temp_numpy\n",
        "\n",
        "def shifting_sound(data,  roll_rate=0.3):\n",
        "    # 그냥 [1, 2, 3, 4] 를 [4, 1, 2, 3]으로 만들어주는건데 이게 효과있는지는 잘 모르겠\n",
        "    data_roll = np.roll(data, int(len(data) * roll_rate))\n",
        "    return data_roll\n",
        "\n",
        "def stretch_sound(data, rate=0.7):\n",
        "    # stretch 해주는거 비율이 뭐가 좋은지 잘모르겟, 0.8이랑, 1.2랑 차이가 안나는거 같음\n",
        "    stretch_data = librosa.effects.time_stretch(data, rate)\n",
        "    return stretch_data\n",
        "\n",
        "def reverse_sound(data):\n",
        "    temp_array = []\n",
        "    for i in range(len(data)):\n",
        "        temp_array.append(data[len(data)-1-i])\n",
        "    temp_numpy =np.asarray(temp_array)\n",
        "    return temp_numpy\n",
        "\n",
        "def adding_white_noise(file_path, sr=22050, noise_quite=25):\n",
        "    current_dir = '/content/drive/My Drive/tobigs/snorrr2/'\n",
        "    noise_dir = os.path.join(current_dir, 'noise')\n",
        "    sound_file = AudioSegment.from_file(file_path)\n",
        "    # 길이 만큼 random 돌려서 걔 얻기\n",
        "    file_list = os.listdir(noise_dir)\n",
        "    noise_file_idx = np.random.randint(0,len(file_list))\n",
        "    noise_file = AudioSegment.from_file(os.path.join(noise_dir,file_list[noise_file_idx]))\n",
        "    noise_file = noise_file-noise_quite\n",
        "    new_sound = sound_file.overlay(noise_file)\n",
        "    new_sound.export(os.path.join(current_dir, 'temp.mp3'),format='mp3')\n",
        "    \n",
        "    wav,sr = librosa.load(os.path.join(current_dir, 'temp.mp3'),sr=sr)\n",
        "    return wav"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFv9INneDQIu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_mfcc(file_path, isTrain, sr=None, n_fft=2048, hop_length=512, n_mels=128, fmin=20, fmax=8300, top_db=80):\n",
        "    #train에만 aug\n",
        "    if(isTrain==True):\n",
        "      switch = np.random.randint(0,3)\n",
        "      wav,sr = librosa.load(file_path,sr=sr)\n",
        "\n",
        "      # if switch==1:\n",
        "      #   wav = adding_white_noise(file_path)\n",
        "      # elif switch==2:\n",
        "      #   # random한 개수만큼 개수만큼  변형하기!\n",
        "      #   aug_num = np.random.randint(1,4)\n",
        "      #   aug_idx_list = np.random.randint(6,size=aug_num)\n",
        "      #   aug_func_list = [shifting_sound, stretch_sound, reverse_sound, partial(freq_augmentation,sr=sr), adding_random_noise, minus_sound]\n",
        "      #   for aug_idx in aug_idx_list:\n",
        "      #     wav = aug_func_list[aug_idx](wav)\n",
        "    else:\n",
        "      wav,sr = librosa.load(file_path,sr=sr)\n",
        "\n",
        "    if wav.shape[0]<5*sr:\n",
        "        wav=np.pad(wav,int(np.ceil((5*sr-wav.shape[0])/2)),mode='reflect')\n",
        "    else:\n",
        "        wav=wav[:5*sr]\n",
        "    mfcc = librosa.feature.mfcc(wav, sr, n_mfcc=50) \n",
        "    return mfcc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7IaRmY3C3Os",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from functools import partial\n",
        "def get_melspectrogram_db(file_path, isTrain, sr=None, n_fft=2048, hop_length=512, n_mels=128, fmin=20, fmax=8300, top_db=80):\n",
        "    #train에만 aug\n",
        "    if(isTrain==True):\n",
        "      switch = np.random.randint(0,3)\n",
        "      wav,sr = librosa.load(file_path,sr=sr)\n",
        "\n",
        "      # if switch==1:\n",
        "      #   wav = adding_white_noise(file_path)\n",
        "      # elif switch==2:\n",
        "      #   # random한 개수만큼 개수만큼  변형하기!\n",
        "      #   aug_num = np.random.randint(1,4)\n",
        "      #   aug_idx_list = np.random.randint(6,size=aug_num)\n",
        "      #   aug_func_list = [shifting_sound, stretch_sound, reverse_sound, partial(freq_augmentation,sr=sr), adding_random_noise, minus_sound]\n",
        "      #   for aug_idx in aug_idx_list:\n",
        "      #     wav = aug_func_list[aug_idx](wav)\n",
        "    else:\n",
        "      wav,sr = librosa.load(file_path,sr=sr)\n",
        "\n",
        "    if wav.shape[0]<5*sr:\n",
        "        wav=np.pad(wav,int(np.ceil((5*sr-wav.shape[0])/2)),mode='reflect')\n",
        "    else:\n",
        "        wav=wav[:5*sr]\n",
        "        \n",
        "    spec=librosa.feature.melspectrogram(wav, sr=sr, n_fft=n_fft,hop_length=hop_length,n_mels=n_mels,fmin=fmin,fmax=fmax)\n",
        "    spec_db=librosa.power_to_db(spec,top_db=top_db)\n",
        "    return spec_db\n",
        "\n",
        "def spec_to_image(spec, eps=1e-6):\n",
        "    # 이미지 자체를 정규화 해서 비슷한 밝기의 spectrogram이 나오도록 함.\n",
        "    mean = spec.mean()\n",
        "    std = spec.std()\n",
        "    spec_norm = (spec - mean) / (std + eps)\n",
        "    # spec_min, spec_max = spec_norm.min(), spec_norm.max()\n",
        "    # spec_scaled = (spec_norm - spec_min) / (spec_max - spec_min)\n",
        "    # spec_scaled = spec_scaled.astype(np.uint8)\n",
        "    return spec_norm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VfAENDWaf2GU",
        "colab_type": "code",
        "outputId": "c2da04f9-2ee7-4000-9946-9d4e25d2fc51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 96
        }
      },
      "source": [
        "from keras.utils import Sequence\n",
        "class DataGenerator(Sequence):\n",
        "    def __init__(self, df, batch_size, shuffle = True, train=False, use_mfcc =True):\n",
        "        self.X = list(df['file_name'])\n",
        "        self.y = list(df['labels'])\n",
        "        self.batch_size = batch_size\n",
        "        self.shuffle = shuffle\n",
        "        self.on_epoch_end()\n",
        "        self.use_mfcc= use_mfcc\n",
        "        self.train=train\n",
        "        \n",
        "    def on_epoch_end(self):\n",
        "        self.indexes = np.arange(len(self.X))\n",
        "        if self.shuffle:\n",
        "            np.random.shuffle(self.indexes)\n",
        "    def __len__(self):\n",
        "        return int(np.floor(len(self.X) / self.batch_size))\n",
        "    \n",
        "    def __data_generation(self, X_list, y_list):\n",
        "        X = []\n",
        "        y = []\n",
        "        \n",
        "        for i, (img_dir, label) in enumerate(zip(X_list, y_list)):\n",
        "          if label == 1:\n",
        "              audio_path = os.path.join(path1, img_dir)\n",
        "          elif label ==2:\n",
        "              audio_path = os.path.join(path2, img_dir)\n",
        "          elif label == 3:\n",
        "              audio_path = os.path.join(path3, img_dir)\n",
        "          elif label == 4:\n",
        "              audio_path = os.path.join(path4, img_dir)\n",
        "          elif label == 5:\n",
        "              audio_path = os.path.join(path5, img_dir)\n",
        "          ### mfcc 쓸지 mel 쓸지\n",
        "          if use_mfcc==False:\n",
        "            image = get_melspectrogram_db(audio_path, self.train)\n",
        "          else:\n",
        "            image = get_mfcc(audio_path, self.train)\n",
        "          ### 정규화하기\n",
        "          image = spec_to_image(image)\n",
        "          ### RGB로 바꾸기\n",
        "          image = np.expand_dims(image, axis=2)\n",
        "          image = np.repeat(image,3,axis=2)\n",
        "          ### label True False로 바꾸기\n",
        "          if label ==3:\n",
        "            label = 1\n",
        "          else:\n",
        "            label = 0\n",
        "          # print(image.shape)\n",
        "          X.append(image)\n",
        "          one_hot_label= [0,0]\n",
        "          one_hot_label[label] = 1\n",
        "          y.append(np.array(one_hot_label))\n",
        "        \n",
        "        # batch size 만큼 있던거 stack하기\n",
        "        X = np.stack(X, axis=0)\n",
        "        y = np.stack(y, axis=0)\n",
        "        # print(X.shape,y.shape)\n",
        "        return X, y\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        indexes = self.indexes[index * self.batch_size : (index + 1) * self.batch_size]\n",
        "        X_list = [self.X[k] for k in indexes]\n",
        "        y_list = [self.y[k] for k in indexes]\n",
        "        X, y = self.__data_generation(X_list, y_list)\n",
        "        # print('get')\n",
        "        return X, y"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g6MbQYJJwc0K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Keras\n",
        "train_generator = DataGenerator(train_df, 5, train=True)\n",
        "# valid_generator = DataGenerator(valid_df, 5)\n",
        "test_generator = DataGenerator(test_df, 3, shuffle=False)\n",
        "\n",
        "\n",
        "# # pytorch는 generator랑 \n",
        "# dataset_train = TrainDatasetBool(df=train_df,\n",
        "#                             img_dir=\"./\",\n",
        "#                             transforms=aug_train, isTrain=True, use_mfcc=use_mfcc)\n",
        "\n",
        "# test_generator = TrainDatasetBool(df=test_df,\n",
        "#                             img_dir=\"./\",\n",
        "#                             transforms=aug_test, isTrain=False, use_mfcc=use_mfcc)\n",
        "\n",
        "\n",
        "# train_loader = DataLoader(dataset=dataset_train, batch_size=64, shuffle=False)\n",
        "# #1576/32(batch 수) -> 50개\n",
        "# test_loader = DataLoader(dataset=dataset_test, batch_size=32, shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-6j_7y2cAhC",
        "colab_type": "code",
        "outputId": "3a66d198-e9c6-4c9f-8a66-4ea158523440",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(train_generator), len(test_generator)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(807, 577)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fxZc2f3FFmw5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_classes = 2\n",
        "lr = 3e-3 # 0.003정도\n",
        "eta_min = 1e-5\n",
        "t_max = 10\n",
        "num_epochs = 20\n",
        "use_mfcc = True\n",
        "# use_mfcc = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fKhpHEMY8a3Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.optimizers import Adam\n",
        "opt = Adam(lr=lr, beta_1=0.9, beta_2=0.999, decay=0.01)\n",
        "\n",
        "### torch\n",
        "# criterion = nn.CrossEntropyLoss().cuda()\n",
        "# # 모델 전체 params 넣음\n",
        "# optimizer = Adam(params=model.parameters(), lr=lr, amsgrad=False)\n",
        "# #  lr을 cosine 함수의 형태처럼 변화시킨다. lr이 커졌다가 작아졌다가 한다. optimizer 가 변수로 들어가 있음\n",
        "# scheduler = CosineAnnealingLR(optimizer, T_max=t_max, eta_min=eta_min)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pV_3E_HSNhh1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import backend as K\n",
        "import tensorflow as tf\n",
        "def auc(y_true, y_pred):\n",
        "    auc = tf.metrics.auc(y_true, y_pred)[1]\n",
        "    K.get_session().run(tf.local_variables_initializer())\n",
        "    return auc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "chlh06dzC6WN",
        "colab_type": "code",
        "outputId": "6f2c7ba4-4e4e-47d6-fce8-bd8a543083ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        }
      },
      "source": [
        "# Keras Model\n",
        "from keras.applications.mobilenet_v2 import MobileNetV2\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense, GlobalAveragePooling2D\n",
        "\n",
        "# classes 도 줄이고 싶은데 weight가 sepcified될떄는 안된대서 일단 1000개로\n",
        "# include_top 빼면 로딩이 되긴 하는데 안빼면 좋을텥데\n",
        "base_model = MobileNetV2(input_shape=(50, 431, 3),weights='imagenet',include_top=False)\n",
        "# include_top 뺐으니까 다시 추가해줘야지\n",
        "x = base_model.output\n",
        "# https://keras.io/layers/pooling/\n",
        "# Pooling2D로 데이터를 2차원으로 만들어버린다!(batch_size, rows, cols, channels)-> (batch_size, value)\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "predictions = Dense(num_classes, activation='softmax')(x)\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# preds = model.predict(x)\n",
        "# decode the results into a list of tuples (class, description, probability)\n",
        "# (one such list for each sample in the batch)\n",
        "# print('Predicted:', decode_predictions(preds, top=3)[0])\n",
        "# Predicted: [(u'n02504013', u'Indian_elephant', 0.82658225), (u'n01871265', u'tusker', 0.1122357), (u'n02504458', u'African_elephant', 0.061040461)]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GjAs88C67NPC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6TnymhxD3flh",
        "colab_type": "code",
        "outputId": "490bb5c2-e745-49b2-d4cb-99c66cba9b72",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 457
        }
      },
      "source": [
        "from keras.callbacks import BaseLogger,Callback\n",
        "# 마지막 레이어만 학습하기\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=[\"accuracy\", auc])\n",
        "\n",
        "model.fit(x=train_generator,\n",
        "          epochs = 5)     \n",
        "\n",
        "# model.fit_generator(generator=train_generator,\n",
        "#                     validation_data=valid_generator,\n",
        "#                     epochs = 2)     "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/metrics_impl.py:808: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Epoch 1/5\n",
            "807/807 [==============================] - 2880s 4s/step - loss: 0.5460 - acc: 0.7688 - auc: 0.7978\n",
            "Epoch 2/5\n",
            "807/807 [==============================] - 1731s 2s/step - loss: 0.4251 - acc: 0.8079 - auc: 0.8540\n",
            "Epoch 3/5\n",
            "807/807 [==============================] - 1748s 2s/step - loss: 0.4214 - acc: 0.8050 - auc: 0.8669\n",
            "Epoch 4/5\n",
            "807/807 [==============================] - 1789s 2s/step - loss: 0.4248 - acc: 0.8064 - auc: 0.8740\n",
            "Epoch 5/5\n",
            "807/807 [==============================] - 1742s 2s/step - loss: 0.4161 - acc: 0.8146 - auc: 0.8769\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fec3f38d9b0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1iqgOz_4JlKH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for layer in model.layers:\n",
        "    layer.trainable = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tx47RSQvDrNB",
        "colab_type": "code",
        "outputId": "29eb97b7-3704-4a84-ccce-f9e6f32e2d78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 154
        }
      },
      "source": [
        "# compile을 해야 train 바꾼것들이 적용 되지!\n",
        "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=[\"accuracy\", auc])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/metrics_impl.py:808: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Zg_of13Nv6b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model 괜찮을때만 저장하기\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "# keras.callbacks.ModelCheckpoint(filepath, monitor='val_loss', verbose=0, save_best_only=False, save_weights_only=False, mode='auto', period=1)\n",
        "# monitor = 어떤거 바탕으로 파악할거냐\n",
        "# verbose 콘솔창에 어떻게 띄울지\n",
        "# save_bast_only\n",
        "# mode 최대값을 볼건지, 최소값을ㅇ 볼건지, monitor를 보고 알아서 파악할건지\n",
        "MODEL_SAVE_PATH = './model/'\n",
        "if not os.path.exists(MODEL_SAVE_PATH):\n",
        "  os.mkdir(MODEL_SAVE_PATH)\n",
        "# 저장할 파일 이름(저 괄호는 알아서 적어주는거겠지?)\n",
        "model_path = MODEL_SAVE_PATH + '{epoch:02d}-{acc:.4f}_weight.hdf5'\n",
        "cb_checkpoint = ModelCheckpoint(model_path,monitor='acc', verbose=0,\n",
        "                                save_best_only=False,\n",
        "                                save_weights_only=True,\n",
        "                                mode='auto', period=1)\n",
        "\n",
        "from keras.callbacks import EarlyStopping\n",
        "# patience 해당 값이 안올라 가는 걸 몇번 허용하냐\n",
        "# min_delta 어느정도 오차는 성능이 안나아졌다고 할거냐?\n",
        "cb_earlystopping = EarlyStopping(monitor='acc', \n",
        "                            min_delta=0, patience=5, verbose=0, \n",
        "                            mode='auto', baseline=None, \n",
        "                            restore_best_weights=False)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJqfhB7Ygqf-",
        "colab_type": "code",
        "outputId": "f58efbd7-253c-4e8c-db07-7413ad67955f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 706
        }
      },
      "source": [
        "# fit으로 하니까 되긴 되네..\n",
        "# history = LossHistory()\n",
        "model.fit(x=train_generator,\n",
        "          epochs = 20,\n",
        "          callbacks = [cb_checkpoint, cb_earlystopping])     "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "807/807 [==============================] - 1940s 2s/step - loss: 0.3942 - acc: 0.8275 - auc: 0.8699\n",
            "Epoch 2/20\n",
            "807/807 [==============================] - 1937s 2s/step - loss: 0.2866 - acc: 0.8778 - auc: 0.9196\n",
            "Epoch 3/20\n",
            "807/807 [==============================] - 1970s 2s/step - loss: 0.2341 - acc: 0.9081 - auc: 0.9377\n",
            "Epoch 4/20\n",
            "807/807 [==============================] - 1984s 2s/step - loss: 0.1775 - acc: 0.9306 - auc: 0.9498\n",
            "Epoch 5/20\n",
            "807/807 [==============================] - 1983s 2s/step - loss: 0.1718 - acc: 0.9309 - auc: 0.9583\n",
            "Epoch 6/20\n",
            "807/807 [==============================] - 1976s 2s/step - loss: 0.1232 - acc: 0.9532 - auc: 0.9648\n",
            "Epoch 7/20\n",
            "807/807 [==============================] - 1985s 2s/step - loss: 0.1128 - acc: 0.9556 - auc: 0.9699\n",
            "Epoch 8/20\n",
            "807/807 [==============================] - 1968s 2s/step - loss: 0.0944 - acc: 0.9631 - auc: 0.9740\n",
            "Epoch 9/20\n",
            "807/807 [==============================] - 1990s 2s/step - loss: 0.0777 - acc: 0.9715 - auc: 0.9774\n",
            "Epoch 10/20\n",
            "807/807 [==============================] - 1963s 2s/step - loss: 0.0703 - acc: 0.9745 - auc: 0.9802\n",
            "Epoch 11/20\n",
            "807/807 [==============================] - 1930s 2s/step - loss: 0.0589 - acc: 0.9782 - auc: 0.9825\n",
            "Epoch 12/20\n",
            "807/807 [==============================] - 2009s 2s/step - loss: 0.0418 - acc: 0.9846 - auc: 0.9846\n",
            "Epoch 13/20\n",
            "807/807 [==============================] - 2011s 2s/step - loss: 0.0482 - acc: 0.9812 - auc: 0.9863\n",
            "Epoch 14/20\n",
            "807/807 [==============================] - 2012s 2s/step - loss: 0.0508 - acc: 0.9822 - auc: 0.9875\n",
            "Epoch 15/20\n",
            "807/807 [==============================] - 2014s 2s/step - loss: 0.0417 - acc: 0.9846 - auc: 0.9886\n",
            "Epoch 16/20\n",
            "807/807 [==============================] - 2012s 2s/step - loss: 0.0283 - acc: 0.9898 - auc: 0.9897\n",
            "Epoch 17/20\n",
            "807/807 [==============================] - 2012s 2s/step - loss: 0.0255 - acc: 0.9901 - auc: 0.9906\n",
            "Epoch 18/20\n",
            "807/807 [==============================] - 2027s 3s/step - loss: 0.0266 - acc: 0.9896 - auc: 0.9914\n",
            "Epoch 19/20\n",
            "807/807 [==============================] - 2007s 2s/step - loss: 0.0315 - acc: 0.9898 - auc: 0.9921\n",
            "Epoch 20/20\n",
            "807/807 [==============================] - 2027s 3s/step - loss: 0.0260 - acc: 0.9916 - auc: 0.9926\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7feb93421fd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MrH-4Mp7NlC9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# validaiton 넣으면 계속 hang\n",
        "# model.fit_generator(generator=train_generator,\n",
        "#                     validation_data=valid_generator,\n",
        "#                     epochs = 20,\n",
        "#                     callbacks = [cb_checkpoint, cb_earlystopping])    \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QrSVIVVcQiaa",
        "colab_type": "code",
        "outputId": "56678a78-dc55-4361-c817-93ac294806bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "model.evaluate(x=test_generator)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "577/577 [==============================] - 1397s 2s/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.35524360412433487, 0.9127671908671149, 0.9924933505430172]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tN5Io-BkPkQt",
        "colab_type": "text"
      },
      "source": [
        "# evaluate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WcPM9McxKg5j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.load_weights(\"./model/17-0.9901_weight.hdf5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RXvLPElYgr3j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "16c7ab4b-4fad-41d8-a93a-c2e49518e2b8"
      },
      "source": [
        "model.evaluate(x=test_generator)"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "577/577 [==============================] - 618s 1s/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.37685767638781276, 0.9185441984977425, 0.9606472626715847]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w2OdnHUSPtbz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# shuffle은 False되어있어야\n",
        "predict = model.predict(test_generator)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LB5t43hDjHPY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "ae1f2959-7f23-40c3-a1a7-32f9f5ea18b7"
      },
      "source": [
        "predict"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[9.9975413e-01, 2.4588330e-04],\n",
              "       [9.9999857e-01, 1.3785061e-06],\n",
              "       [9.9950373e-01, 4.9621036e-04],\n",
              "       ...,\n",
              "       [1.0000000e+00, 4.2583217e-08],\n",
              "       [9.3533248e-01, 6.4667530e-02],\n",
              "       [9.9939501e-01, 6.0494599e-04]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qm7CbEVOcUpD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred_bool = np.argmax(predict, axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iuP3NrbHjKCF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "24ba7a7f-a7ed-4534-e16d-06c2a74598ee"
      },
      "source": [
        "pred_bool[0:30]"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0,\n",
              "       1, 0, 1, 0, 1, 0, 0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJ3jX_JzjKAc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "ca295a2a-324a-49fa-9817-e2e86dd0399c"
      },
      "source": [
        "(test_df.loc[0:30,'labels']==True).to_numpy()"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([False, False,  True, False,  True,  True, False, False,  True,\n",
              "       False, False,  True, False, False, False,  True, False, False,\n",
              "       False, False, False,  True, False, False,  True, False, False,\n",
              "        True, False,  True, False])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gMFOeIzceRa8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "real = test_df.loc[:len(test_df)-2,'labels']==3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PDguVBtnfs9k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "real_np = real.apply(lambda x: 1 if x==True else 0).to_numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KByYyajQUGA3",
        "colab_type": "code",
        "outputId": "e8abd42f-5989-4d89-a447-0af348bb86bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        }
      },
      "source": [
        "# pred_bool = np.argmax(predict, axis=1)\n",
        "\n",
        "# 3개에 나누어 떨어지는 만큼만 train을 해서 하나가 모자름\n",
        "print(classification_report(real_np, pred_bool))"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.98      0.94      1077\n",
            "           1       0.95      0.82      0.88       654\n",
            "\n",
            "    accuracy                           0.92      1731\n",
            "   macro avg       0.93      0.90      0.91      1731\n",
            "weighted avg       0.92      0.92      0.92      1731\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kX76eDiJdazM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}