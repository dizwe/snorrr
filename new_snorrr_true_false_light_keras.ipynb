{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "new_snorrr_true_false_light_keras.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "Wau96yf3kimd"
      ],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "GqS5C8mDYxgg",
        "colab_type": "code",
        "outputId": "dfe12491-3466-448d-8b1c-7e8f9d3662f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "al6q3XALYrw_",
        "colab_type": "code",
        "outputId": "965c0f31-500d-436c-95ca-fbafb7ede8e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd /content/drive/My\\ Drive/tobigs/snorrr2"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/tobigs/snorrr2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pvKS_cpfjEeS",
        "colab_type": "code",
        "outputId": "df54283c-9126-4be0-ac13-0f7c1c6c787a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "# !unzip raw_data.zip -d data/\n",
        "!pip install pydub"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pydub\n",
            "  Downloading https://files.pythonhosted.org/packages/79/db/eaf620b73a1eec3c8c6f8f5b0b236a50f9da88ad57802154b7ba7664d0b8/pydub-0.23.1-py2.py3-none-any.whl\n",
            "Installing collected packages: pydub\n",
            "Successfully installed pydub-0.23.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rkBnj-nQBabI",
        "colab_type": "code",
        "outputId": "a045e035-a445-49cb-b2c7-c4d52f2758f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "ls"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mdata\u001b[0m/             new_snorrr_true_false.ipynb              raw_data.zip\n",
            "\u001b[01;34mdata_small_test\u001b[0m/  new_snorrr_true_false_light.ipynb        temp.mp3\n",
            "\u001b[01;34mmodel\u001b[0m/            new_snorrr_true_false_light_keras.ipynb  \u001b[01;34mweight\u001b[0m/\n",
            "new_snorrr.ipynb  \u001b[01;34mnoise\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wau96yf3kimd",
        "colab_type": "text"
      },
      "source": [
        "## audio.csv 만들기\n",
        "(파일 겹치는건 빼기)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lHZmp-t9kht2",
        "colab_type": "code",
        "outputId": "e0904ada-25cc-4b6e-8060-e76d4312f5e8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cd /content/drive/My\\ Drive/tobigs/snorrr2/data"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/tobigs/snorrr2/data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cvbpvnfUqcm8",
        "colab_type": "code",
        "outputId": "10b07bdf-9ad0-475a-b144-251906ca9f6b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34m'Male speech, man speaking'\u001b[0m/   \u001b[01;34msnoring\u001b[0m/                         \u001b[01;34mVehicle\u001b[0m/\n",
            "\u001b[01;34m'Outside, rural or natural'\u001b[0m/  \u001b[01;34m'Traffic noise, roadway noise'\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Slh3aa05kvWW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "label_info = ['Male speech, man speaking','Outside, rural or natural','snoring','Traffic noise, roadway noise','Vehicle']\n",
        "df = pd.DataFrame({\"file_name\":[], \"labels\":[]})\n",
        "for label in os.listdir():\n",
        "  if label=='__MACOSX':\n",
        "      continue\n",
        "  label_dir = os.path.join(os.getcwd(), label)\n",
        "  current_label_num = label_info.index(label)+1\n",
        "  for file in os.listdir(label_dir):\n",
        "    if file.endswith(\"mp3\"):\n",
        "      df = df.append({\"file_name\":file, \"labels\":int(current_label_num)} , ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hr3J5JVVuUq5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.labels = df['labels'].astype(int)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ul6ZEd68v700",
        "colab_type": "code",
        "outputId": "d07b392d-10fe-437a-f7b3-75da7605e9c5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "df[df.file_name.duplicated()]['file_name']"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "82     3353.mp3\n",
              "107    2550.mp3\n",
              "112    2933.mp3\n",
              "134    2762.mp3\n",
              "147    1705.mp3\n",
              "149    3272.mp3\n",
              "157    2536.mp3\n",
              "225    1522.mp3\n",
              "Name: file_name, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SgAsCM79vSDh",
        "colab_type": "code",
        "outputId": "5db26bcf-9cee-4278-c857-916da1fe2693",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "df[df['file_name'].str.find('5487.mp3')!=-1]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>file_name</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>241</th>\n",
              "      <td>5487.mp3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    file_name  labels\n",
              "241  5487.mp3       1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-yHnU0U4qakz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 중복되는건 삭제하기\n",
        "df = df[df['file_name'].isin(df[df.file_name.duplicated()]['file_name'])==False]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUsHOb6Mzqrh",
        "colab_type": "code",
        "outputId": "3444b61b-5f58-41ac-911e-a698bbaa929f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "len(df)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "227"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ULbZlXJHwxDt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.to_csv('audio.csv',index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Rc_LfVWknpm",
        "colab_type": "text"
      },
      "source": [
        "## 학습하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oWFQ2pxQks24",
        "colab_type": "code",
        "outputId": "04eec296-1e48-40d4-b9f9-fdc22432539f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd /content/drive/My\\ Drive/tobigs/snorrr2"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/tobigs/snorrr2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "seP-nzVrfSPX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import librosa\n",
        "import pydub \n",
        "from fastprogress import master_bar, progress_bar\n",
        "import numpy as np\n",
        "import time\n",
        "import os\n",
        "import warnings\n",
        "from sklearn.metrics import classification_report"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yr1e22pMBNqn",
        "colab_type": "code",
        "outputId": "83642f8f-475b-45c1-a34f-b2eac6731720",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "warnings.filterwarnings(action=\"ignore\")\n",
        "\n",
        "path1 = \"./data/Male speech, man speaking\"\n",
        "path2 = \"./data/Outside, rural or natural\"\n",
        "path3 = \"./data/snoring\"\n",
        "path4 = \"./data/Traffic noise, roadway noise\"\n",
        "path5 = \"./data/Vehicle\"\n",
        "\n",
        "df = pd.read_csv(\"./data/audio.csv\")\n",
        "train_df, test_df = train_test_split(df, test_size=0.3, random_state=42) \n",
        "# train_df, valid_df = train_test_split(df, test_size=0.2, random_state=42) \n",
        "\n",
        "train_df = train_df.reset_index()\n",
        "# valid_df = valid_df.reset_index()\n",
        "test_df = test_df.reset_index()\n",
        "print(train_df[\"labels\"].value_counts())\n",
        "# print(valid_df[\"labels\"].value_counts())"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3    1461\n",
            "1    1039\n",
            "2     742\n",
            "5     491\n",
            "4     306\n",
            "Name: labels, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-OhsmPrBs-5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pydub import AudioSegment\n",
        "def freq_augmentation(y, sr):\n",
        "    switch = np.random.randint(1,3)\n",
        "    if(switch==1): #고음\n",
        "        rate = np.random.uniform(2, 5)\n",
        "    elif(switch==2): #저음\n",
        "        rate = np.random.uniform(-5, -2)\n",
        "    y = librosa.effects.pitch_shift(y, sr, n_steps=rate)\n",
        "    return y\n",
        "\n",
        "def adding_random_noise(y, noise_rate=0.005):\n",
        "    rn = np.random.randn(len(y))\n",
        "    data_rn = y + noise_rate*rn\n",
        "    return data_rn\n",
        "\n",
        "def minus_sound(y):\n",
        "    temp_numpy = (-1)*y\n",
        "    return temp_numpy\n",
        "\n",
        "def shifting_sound(data,  roll_rate=0.3):\n",
        "    # 그냥 [1, 2, 3, 4] 를 [4, 1, 2, 3]으로 만들어주는건데 이게 효과있는지는 잘 모르겠\n",
        "    data_roll = np.roll(data, int(len(data) * roll_rate))\n",
        "    return data_roll\n",
        "\n",
        "def stretch_sound(data, rate=0.7):\n",
        "    # stretch 해주는거 비율이 뭐가 좋은지 잘모르겟, 0.8이랑, 1.2랑 차이가 안나는거 같음\n",
        "    stretch_data = librosa.effects.time_stretch(data, rate)\n",
        "    return stretch_data\n",
        "\n",
        "def reverse_sound(data):\n",
        "    temp_array = []\n",
        "    for i in range(len(data)):\n",
        "        temp_array.append(data[len(data)-1-i])\n",
        "    temp_numpy =np.asarray(temp_array)\n",
        "    return temp_numpy\n",
        "\n",
        "def adding_white_noise(file_path, sr=22050, noise_quite=25):\n",
        "    current_dir = '/content/drive/My Drive/tobigs/snorrr2/'\n",
        "    noise_dir = os.path.join(current_dir, 'noise')\n",
        "    sound_file = AudioSegment.from_file(file_path)\n",
        "    # 길이 만큼 random 돌려서 걔 얻기\n",
        "    file_list = os.listdir(noise_dir)\n",
        "    noise_file_idx = np.random.randint(0,len(file_list))\n",
        "    noise_file = AudioSegment.from_file(os.path.join(noise_dir,file_list[noise_file_idx]))\n",
        "    noise_file = noise_file-noise_quite\n",
        "    new_sound = sound_file.overlay(noise_file)\n",
        "    new_sound.export(os.path.join(current_dir, 'temp.mp3'),format='mp3')\n",
        "    \n",
        "    wav,sr = librosa.load(os.path.join(current_dir, 'temp.mp3'),sr=sr)\n",
        "    return wav"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFv9INneDQIu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_mfcc(file_path, isTrain, sr=None, n_fft=2048, hop_length=512, n_mels=128, fmin=20, fmax=8300, top_db=80):\n",
        "    #train에만 aug\n",
        "    if(isTrain==True):\n",
        "      switch = np.random.randint(0,3)\n",
        "      wav,sr = librosa.load(file_path,sr=sr)\n",
        "\n",
        "      # if switch==1:\n",
        "      #   wav = adding_white_noise(file_path)\n",
        "      # elif switch==2:\n",
        "      #   # random한 개수만큼 개수만큼  변형하기!\n",
        "      #   aug_num = np.random.randint(1,4)\n",
        "      #   aug_idx_list = np.random.randint(6,size=aug_num)\n",
        "      #   aug_func_list = [shifting_sound, stretch_sound, reverse_sound, partial(freq_augmentation,sr=sr), adding_random_noise, minus_sound]\n",
        "      #   for aug_idx in aug_idx_list:\n",
        "      #     wav = aug_func_list[aug_idx](wav)\n",
        "    else:\n",
        "      wav,sr = librosa.load(file_path,sr=sr)\n",
        "\n",
        "    if wav.shape[0]<5*sr:\n",
        "        wav=np.pad(wav,int(np.ceil((5*sr-wav.shape[0])/2)),mode='reflect')\n",
        "    else:\n",
        "        wav=wav[:5*sr]\n",
        "    mfcc = librosa.feature.mfcc(wav, sr, n_mfcc=50) \n",
        "    return mfcc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7IaRmY3C3Os",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from functools import partial\n",
        "def get_melspectrogram_db(file_path, isTrain, sr=None, n_fft=2048, hop_length=512, n_mels=128, fmin=20, fmax=8300, top_db=80):\n",
        "    #train에만 aug\n",
        "    if(isTrain==True):\n",
        "      switch = np.random.randint(0,3)\n",
        "      wav,sr = librosa.load(file_path,sr=sr)\n",
        "\n",
        "      # if switch==1:\n",
        "      #   wav = adding_white_noise(file_path)\n",
        "      # elif switch==2:\n",
        "      #   # random한 개수만큼 개수만큼  변형하기!\n",
        "      #   aug_num = np.random.randint(1,4)\n",
        "      #   aug_idx_list = np.random.randint(6,size=aug_num)\n",
        "      #   aug_func_list = [shifting_sound, stretch_sound, reverse_sound, partial(freq_augmentation,sr=sr), adding_random_noise, minus_sound]\n",
        "      #   for aug_idx in aug_idx_list:\n",
        "      #     wav = aug_func_list[aug_idx](wav)\n",
        "    else:\n",
        "      wav,sr = librosa.load(file_path,sr=sr)\n",
        "\n",
        "    if wav.shape[0]<5*sr:\n",
        "        wav=np.pad(wav,int(np.ceil((5*sr-wav.shape[0])/2)),mode='reflect')\n",
        "    else:\n",
        "        wav=wav[:5*sr]\n",
        "        \n",
        "    spec=librosa.feature.melspectrogram(wav, sr=sr, n_fft=n_fft,hop_length=hop_length,n_mels=n_mels,fmin=fmin,fmax=fmax)\n",
        "    spec_db=librosa.power_to_db(spec,top_db=top_db)\n",
        "    return spec_db\n",
        "\n",
        "def spec_to_image(spec, eps=1e-6):\n",
        "    # 이미지 자체를 정규화 해서 비슷한 밝기의 spectrogram이 나오도록 함.\n",
        "    mean = spec.mean()\n",
        "    std = spec.std()\n",
        "    spec_norm = (spec - mean) / (std + eps)\n",
        "    # spec_min, spec_max = spec_norm.min(), spec_norm.max()\n",
        "    # spec_scaled = (spec_norm - spec_min) / (spec_max - spec_min)\n",
        "    # spec_scaled = spec_scaled.astype(np.uint8)\n",
        "    return spec_norm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VfAENDWaf2GU",
        "colab_type": "code",
        "outputId": "fda584bc-3168-4361-d54f-e59e73c8e4e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 96
        }
      },
      "source": [
        "from keras.utils import Sequence\n",
        "class DataGenerator(Sequence):\n",
        "    def __init__(self, df, batch_size, shuffle = True, train=False, use_mfcc =True):\n",
        "        self.X = list(df['file_name'])\n",
        "        self.y = list(df['labels'])\n",
        "        self.batch_size = batch_size\n",
        "        self.shuffle = shuffle\n",
        "        self.on_epoch_end()\n",
        "        self.use_mfcc= use_mfcc\n",
        "        self.train=train\n",
        "        \n",
        "    def on_epoch_end(self):\n",
        "        self.indexes = np.arange(len(self.X))\n",
        "        if self.shuffle:\n",
        "            np.random.shuffle(self.indexes)\n",
        "    def __len__(self):\n",
        "        return int(np.floor(len(self.X) / self.batch_size))\n",
        "    \n",
        "    def __data_generation(self, X_list, y_list):\n",
        "        X = []\n",
        "        y = []\n",
        "        \n",
        "        for i, (img_dir, label) in enumerate(zip(X_list, y_list)):\n",
        "          if label == 1:\n",
        "              audio_path = os.path.join(path1, img_dir)\n",
        "          elif label ==2:\n",
        "              audio_path = os.path.join(path2, img_dir)\n",
        "          elif label == 3:\n",
        "              audio_path = os.path.join(path3, img_dir)\n",
        "          elif label == 4:\n",
        "              audio_path = os.path.join(path4, img_dir)\n",
        "          elif label == 5:\n",
        "              audio_path = os.path.join(path5, img_dir)\n",
        "          ### mfcc 쓸지 mel 쓸지\n",
        "          if use_mfcc==False:\n",
        "            image = get_melspectrogram_db(audio_path, self.train)\n",
        "          else:\n",
        "            image = get_mfcc(audio_path, self.train)\n",
        "          ### 정규화하기\n",
        "          image = spec_to_image(image)\n",
        "          ### RGB로 바꾸기\n",
        "          image = np.expand_dims(image, axis=2)\n",
        "          image = np.repeat(image,3,axis=2)\n",
        "          ### label True False로 바꾸기\n",
        "          if label ==3:\n",
        "            label = 1\n",
        "          else:\n",
        "            label = 0\n",
        "          # print(image.shape)\n",
        "          X.append(image)\n",
        "          one_hot_label= [0,0]\n",
        "          one_hot_label[label] = 1\n",
        "          y.append(np.array(one_hot_label))\n",
        "        \n",
        "        # batch size 만큼 있던거 stack하기\n",
        "        X = np.stack(X, axis=0)\n",
        "        y = np.stack(y, axis=0)\n",
        "        # print(X.shape,y.shape)\n",
        "        return X, y\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        indexes = self.indexes[index * self.batch_size : (index + 1) * self.batch_size]\n",
        "        X_list = [self.X[k] for k in indexes]\n",
        "        y_list = [self.y[k] for k in indexes]\n",
        "        X, y = self.__data_generation(X_list, y_list)\n",
        "        # print('get')\n",
        "        return X, y"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g6MbQYJJwc0K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Keras\n",
        "train_generator = DataGenerator(train_df, 5, train=True)\n",
        "# valid_generator = DataGenerator(valid_df, 5)\n",
        "test_generator = DataGenerator(test_df, 3)\n",
        "\n",
        "\n",
        "# # pytorch는 generator랑 \n",
        "# dataset_train = TrainDatasetBool(df=train_df,\n",
        "#                             img_dir=\"./\",\n",
        "#                             transforms=aug_train, isTrain=True, use_mfcc=use_mfcc)\n",
        "\n",
        "# test_generator = TrainDatasetBool(df=test_df,\n",
        "#                             img_dir=\"./\",\n",
        "#                             transforms=aug_test, isTrain=False, use_mfcc=use_mfcc)\n",
        "\n",
        "\n",
        "# train_loader = DataLoader(dataset=dataset_train, batch_size=64, shuffle=False)\n",
        "# #1576/32(batch 수) -> 50개\n",
        "# test_loader = DataLoader(dataset=dataset_test, batch_size=32, shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-6j_7y2cAhC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "24c59dad-8e92-4d13-a238-0e85e7dd607c"
      },
      "source": [
        "len(train_generator), len(test_generator)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(807, 577)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fxZc2f3FFmw5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_classes = 2\n",
        "lr = 3e-3 # 0.003정도\n",
        "eta_min = 1e-5\n",
        "t_max = 10\n",
        "num_epochs = 20\n",
        "use_mfcc = True\n",
        "# use_mfcc = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fKhpHEMY8a3Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.optimizers import Adam\n",
        "opt = Adam(lr=lr, beta_1=0.9, beta_2=0.999, decay=0.01)\n",
        "\n",
        "### torch\n",
        "# criterion = nn.CrossEntropyLoss().cuda()\n",
        "# # 모델 전체 params 넣음\n",
        "# optimizer = Adam(params=model.parameters(), lr=lr, amsgrad=False)\n",
        "# #  lr을 cosine 함수의 형태처럼 변화시킨다. lr이 커졌다가 작아졌다가 한다. optimizer 가 변수로 들어가 있음\n",
        "# scheduler = CosineAnnealingLR(optimizer, T_max=t_max, eta_min=eta_min)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pV_3E_HSNhh1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import backend as K\n",
        "import tensorflow as tf\n",
        "def auc(y_true, y_pred):\n",
        "    auc = tf.metrics.auc(y_true, y_pred)[1]\n",
        "    K.get_session().run(tf.local_variables_initializer())\n",
        "    return auc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "chlh06dzC6WN",
        "colab_type": "code",
        "outputId": "ac993760-ac70-43e3-97df-7a23501d13d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 440
        }
      },
      "source": [
        "# Keras Model\n",
        "from keras.applications.mobilenet_v2 import MobileNetV2\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense, GlobalAveragePooling2D\n",
        "\n",
        "# classes 도 줄이고 싶은데 weight가 sepcified될떄는 안된대서 일단 1000개로\n",
        "# include_top 빼면 로딩이 되긴 하는데 안빼면 좋을텥데\n",
        "base_model = MobileNetV2(input_shape=(50, 431, 3),weights='imagenet',include_top=False)\n",
        "# include_top 뺐으니까 다시 추가해줘야지\n",
        "x = base_model.output\n",
        "# https://keras.io/layers/pooling/\n",
        "# Pooling2D로 데이터를 2차원으로 만들어버린다!(batch_size, rows, cols, channels)-> (batch_size, value)\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "predictions = Dense(num_classes, activation='softmax')(x)\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# preds = model.predict(x)\n",
        "# decode the results into a list of tuples (class, description, probability)\n",
        "# (one such list for each sample in the batch)\n",
        "# print('Predicted:', decode_predictions(preds, top=3)[0])\n",
        "# Predicted: [(u'n02504013', u'Indian_elephant', 0.82658225), (u'n01871265', u'tusker', 0.1122357), (u'n02504458', u'African_elephant', 0.061040461)]"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "Downloading data from https://github.com/JonathanCMitchell/mobilenet_v2_keras/releases/download/v1.1/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
            "9412608/9406464 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GjAs88C67NPC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6TnymhxD3flh",
        "colab_type": "code",
        "outputId": "490bb5c2-e745-49b2-d4cb-99c66cba9b72",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 440
        }
      },
      "source": [
        "from keras.callbacks import BaseLogger,Callback\n",
        "# 마지막 레이어만 학습하기\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=[\"accuracy\", auc])\n",
        "\n",
        "model.fit(x=train_generator,\n",
        "          epochs = 5)     \n",
        "\n",
        "# model.fit_generator(generator=train_generator,\n",
        "#                     validation_data=valid_generator,\n",
        "#                     epochs = 2)     "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/metrics_impl.py:808: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Epoch 1/5\n",
            "807/807 [==============================] - 2880s 4s/step - loss: 0.5460 - acc: 0.7688 - auc: 0.7978\n",
            "Epoch 2/5\n",
            "807/807 [==============================] - 1731s 2s/step - loss: 0.4251 - acc: 0.8079 - auc: 0.8540\n",
            "Epoch 3/5\n",
            "807/807 [==============================] - 1748s 2s/step - loss: 0.4214 - acc: 0.8050 - auc: 0.8669\n",
            "Epoch 4/5\n",
            "807/807 [==============================] - 1789s 2s/step - loss: 0.4248 - acc: 0.8064 - auc: 0.8740\n",
            "Epoch 5/5\n",
            "431/807 [===============>..............] - ETA: 13:39 - loss: 0.4179 - acc: 0.8213 - auc: 0.8762"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1iqgOz_4JlKH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for layer in model.layers:\n",
        "    layer.trainable = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tx47RSQvDrNB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# compile을 해야 train 바꾼것들이 적용 되지!\n",
        "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=[\"accuracy\", auc])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Zg_of13Nv6b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model 괜찮을때만 저장하기\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "# keras.callbacks.ModelCheckpoint(filepath, monitor='val_loss', verbose=0, save_best_only=False, save_weights_only=False, mode='auto', period=1)\n",
        "# monitor = 어떤거 바탕으로 파악할거냐\n",
        "# verbose 콘솔창에 어떻게 띄울지\n",
        "# save_bast_only\n",
        "# mode 최대값을 볼건지, 최소값을ㅇ 볼건지, monitor를 보고 알아서 파악할건지\n",
        "MODEL_SAVE_PATH = './model/'\n",
        "if not os.path.exists(MODEL_SAVE_PATH):\n",
        "  os.mkdir(MODEL_SAVE_PATH)\n",
        "# 저장할 파일 이름(저 괄호는 알아서 적어주는거겠지?)\n",
        "model_path = MODEL_SAVE_PATH + '{epoch:02d}-{acc:.4f}_weight.hdf5'\n",
        "cb_checkpoint = ModelCheckpoint(model_path,monitor='acc', verbose=0,\n",
        "                                save_best_only=False,\n",
        "                                save_weights_only=True,\n",
        "                                mode='auto', period=1)\n",
        "\n",
        "from keras.callbacks import EarlyStopping\n",
        "# patience 해당 값이 안올라 가는 걸 몇번 허용하냐\n",
        "# min_delta 어느정도 오차는 성능이 안나아졌다고 할거냐?\n",
        "cb_earlystopping = EarlyStopping(monitor='acc', \n",
        "                            min_delta=0, patience=5, verbose=0, \n",
        "                            mode='auto', baseline=None, \n",
        "                            restore_best_weights=False)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJqfhB7Ygqf-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# fit으로 하니까 되긴 되네..\n",
        "# history = LossHistory()\n",
        "model.fit(x=train_generator,\n",
        "          epochs = 20,\n",
        "          callbacks = [cb_checkpoint, cb_earlystopping])     "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MrH-4Mp7NlC9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# validaiton 넣으면 계속 hang\n",
        "# model.fit_generator(generator=train_generator,\n",
        "#                     validation_data=valid_generator,\n",
        "#                     epochs = 20,\n",
        "#                     callbacks = [cb_checkpoint, cb_earlystopping])    \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QrSVIVVcQiaa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}